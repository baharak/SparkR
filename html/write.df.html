<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Save the contents of the DataFrame to a data source</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for write.df,DataFrame,character-method {SparkR}"><tr><td>write.df,DataFrame,character-method {SparkR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Save the contents of the DataFrame to a data source</h2>

<h3>Description</h3>

<p>The data source is specified by the 'source' and a set of options (...).
If 'source' is not specified, the default data source configured by
spark.sql.sources.default will be used.
</p>


<h3>Usage</h3>

<pre>
## S4 method for signature 'DataFrame,character'
write.df(df, path, source = NULL,
  mode = "append", ...)

## S4 method for signature 'DataFrame,character'
saveDF(df, path, source = NULL,
  mode = "append", ...)

write.df(df, path, ...)

saveDF(df, path, ...)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>df</code></td>
<td>
<p>A SparkSQL DataFrame</p>
</td></tr>
<tr valign="top"><td><code>path</code></td>
<td>
<p>A name for the table</p>
</td></tr>
<tr valign="top"><td><code>source</code></td>
<td>
<p>A name for external data source</p>
</td></tr>
<tr valign="top"><td><code>mode</code></td>
<td>
<p>One of 'append', 'overwrite', 'error', 'ignore'</p>
</td></tr>
</table>


<h3>Details</h3>

<p>Additionally, mode is used to specify the behavior of the save operation when
data already exists in the data source. There are four modes:
append: Contents of this DataFrame are expected to be appended to existing data.
overwrite: Existing data is expected to be overwritten by the contents of
error: An exception is expected to be thrown.
ignore: The save operation is expected to not save the contents of the DataFrame
</p>


<h3>Examples</h3>

<pre><code class="r">## Not run: 
##D sc &lt;- sparkR.init()
##D sqlContext &lt;- sparkRSQL.init(sc)
##D path &lt;- &quot;path/to/file.json&quot;
##D df &lt;- jsonFile(sqlContext, path)
##D write.df(df, &quot;myfile&quot;, &quot;parquet&quot;, &quot;overwrite&quot;)
## End(Not run)
</code></pre>


<hr /><div style="text-align: center;">[Package <em>SparkR</em> version 1.4.0 <a href="00Index.html">Index</a>]</div>
</body></html>
