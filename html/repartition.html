<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><title>R: Repartition</title>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="stylesheet" type="text/css" href="R.css" />

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/styles/github.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/highlight.min.js"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/8.3/languages/r.min.js"></script>
<script>hljs.initHighlightingOnLoad();</script>
</head><body>

<table width="100%" summary="page for repartition,DataFrame,numeric-method {SparkR}"><tr><td>repartition,DataFrame,numeric-method {SparkR}</td><td style="text-align: right;">R Documentation</td></tr></table>

<h2>Repartition</h2>

<h3>Description</h3>

<p>Return a new DataFrame that has exactly numPartitions partitions.
</p>
<p>Return a new RDD that has exactly numPartitions partitions.
Can increase or decrease the level of parallelism in this RDD. Internally,
this uses a shuffle to redistribute data.
If you are decreasing the number of partitions in this RDD, consider using
coalesce, which can avoid performing a shuffle.
</p>


<h3>Usage</h3>

<pre>
## S4 method for signature 'DataFrame,numeric'
repartition(x, numPartitions)

## S4 method for signature 'RDD,numeric'
repartition(x, numPartitions)
</pre>


<h3>Arguments</h3>

<table summary="R argblock">
<tr valign="top"><td><code>x</code></td>
<td>
<p>A SparkSQL DataFrame</p>
</td></tr>
<tr valign="top"><td><code>numPartitions</code></td>
<td>
<p>The number of partitions to use.</p>
</td></tr>
<tr valign="top"><td><code>x</code></td>
<td>
<p>The RDD.</p>
</td></tr>
<tr valign="top"><td><code>numPartitions</code></td>
<td>
<p>Number of partitions to create.</p>
</td></tr>
</table>


<h3>See Also</h3>

<p>coalesce
</p>


<h3>Examples</h3>

<pre><code class="r">## Not run: 
##D sc &lt;- sparkR.init()
##D sqlContext &lt;- sparkRSQL.init(sc)
##D path &lt;- &quot;path/to/file.json&quot;
##D df &lt;- jsonFile(sqlContext, path)
##D newDF &lt;- repartition(df, 2L)
## End(Not run)
## Not run: 
##D sc &lt;- sparkR.init()
##D rdd &lt;- parallelize(sc, list(1, 2, 3, 4, 5, 6, 7), 4L)
##D numPartitions(rdd)                   # 4
##D numPartitions(repartition(rdd, 2L))  # 2
## End(Not run)
</code></pre>


<hr /><div style="text-align: center;">[Package <em>SparkR</em> version 1.4.0 <a href="00Index.html">Index</a>]</div>
</body></html>
